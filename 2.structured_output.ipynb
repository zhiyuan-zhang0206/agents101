{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6251fbbf",
   "metadata": {},
   "source": [
    "## 结构化输出 (Structured Output)\n",
    "\n",
    "在这个notebook中，我们将演示如何让LLM返回结构化的数据格式，而不是纯文本。我们将使用与chatbot相同的例子：求Normal分布的最大似然估计(MLE)。\n",
    "\n",
    "### 为什么需要结构化输出？\n",
    "- 便于程序处理和解析\n",
    "- 减少格式错误\n",
    "- 提高数据的可靠性和一致性\n",
    "- 便于与其他系统集成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f82fd5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage, BaseMessage\n",
    "import dotenv\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "model = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "### 方法一：System Prompt + 手动解析 JSON\n",
    "\n",
    "第一种方法是在system prompt中明确要求模型返回特定的JSON格式，然后手动解析结果。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b8cf055",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始回复:\n",
      "{\n",
      "  \"answer\": \"对于来自正态分布 $N(\\\\mu, \\\\sigma^2)$ 的 $n$ 个独立同分布样本 $x_1, x_2, \\\\ldots, x_n$，其最大似然估计（MLE）公式如下：\\n\\n1.  **均值 $\\\\mu$ 的最大似然估计：**\\n    $\\\\hat{\\\\mu}_{MLE} = \\\\frac{1}{n} \\\\sum_{i=1}^{n} x_i = \\\\bar{x}$\\n    （即样本均值）\\n\\n2.  **方差 $\\\\sigma^2$ 的最大似然估计：**\\n    $\\\\hat{\\\\sigma}^2_{MLE} = \\\\frac{1}{n} \\\\sum_{i=1}^{n} (x_i - \\\\bar{x})^2$\\n    （即有偏样本方差）\",\n",
      "  \"explanation\": \"为了推导正态分布参数 $\\\\mu$ 和 $\\\\sigma^2$ 的最大似然估计，我们首先写出正态分布的概率密度函数（PDF）：\\n$f(x | \\\\mu, \\\\sigma^2) = \\\\frac{1}{\\\\sqrt{2\\\\pi\\\\sigma^2}} e^{-\\\\frac{(x-\\\\mu)^2}{2\\\\sigma^2}}$\\n\\n给定 $n$ 个独立同分布的样本 $X = (x_1, x_2, \\\\ldots, x_n)$，似然函数 $L(\\\\mu, \\\\sigma^2 | X)$ 是各样本 PDF 的乘积：\\n$L(\\\\mu, \\\\sigma^2 | X) = \\\\prod_{i=1}^{n} f(x_i | \\\\mu, \\\\sigma^2) = \\\\prod_{i=1}^{n} \\\\frac{1}{\\\\sqrt{2\\\\pi\\\\sigma^2}} e^{-\\\\frac{(x_i-\\\\mu)^2}{2\\\\sigma^2}}$\\n$L(\\\\mu, \\\\sigma^2 | X) = (2\\\\pi\\\\sigma^2)^{-n/2} e^{-\\\\frac{1}{2\\\\sigma^2} \\\\sum_{i=1}^{n} (x_i-\\\\mu)^2}$\\n\\n为了简化计算，我们通常使用对数似然函数（log-likelihood function），因为对数函数是单调递增的，所以最大化似然函数等价于最大化对数似然函数：\\n$\\\\ln L(\\\\mu, \\\\sigma^2 | X) = \\\\ln \\\\left( (2\\\\pi\\\\sigma^2)^{-n/2} e^{-\\\\frac{1}{2\\\\sigma^2} \\\\sum_{i=1}^{n} (x_i-\\\\mu)^2} \\\\right)$\\n$\\\\ln L(\\\\mu, \\\\sigma^2 | X) = -\\\\frac{n}{2} \\\\ln(2\\\\pi\\\\sigma^2) - \\\\frac{1}{2\\\\sigma^2} \\\\sum_{i=1}^{n} (x_i-\\\\mu)^2$\\n$\\\\ln L(\\\\mu, \\\\sigma^2 | X) = -\\\\frac{n}{2} \\\\ln(2\\\\pi) - \\\\frac{n}{2} \\\\ln(\\\\sigma^2) - \\\\frac{1}{2\\\\sigma^2} \\\\sum_{i=1}^{n} (x_i-\\\\mu)^2$\\n\\n接下来，我们对对数似然函数分别关于 $\\\\mu$ 和 $\\\\sigma^2$ 求偏导，并令其等于零，以找到最大值。\\n\\n**1. 均值 $\\\\mu$ 的最大似然估计：**\\n对 $\\\\ln L$ 关于 $\\\\mu$ 求偏导：\\n$\\\\frac{\\\\partial}{\\\\partial \\\\mu} \\\\ln L = \\\\frac{\\\\partial}{\\\\partial \\\\mu} \\\\left( -\\\\frac{n}{2} \\\\ln(2\\\\pi) - \\\\frac{n}{2} \\\\ln(\\\\sigma^2) - \\\\frac{1}{2\\\\sigma^2} \\\\sum_{i=1}^{n} (x_i-\\\\mu)^2 \\\\right)$\\n$= 0 - 0 - \\\\frac{1}{2\\\\sigma^2} \\\\sum_{i=1}^{n} 2(x_i-\\\\mu)(-1)$\\n$= \\\\frac{1}{\\\\sigma^2} \\\\sum_{i=1}^{n} (x_i-\\\\mu)$\\n\\n令偏导数等于零：\\n$\\\\frac{1}{\\\\sigma^2} \\\\sum_{i=1}^{n} (x_i-\\\\mu) = 0$\\n由于 $\\\\sigma^2 > 0$，我们可以将上式两边乘以 $\\\\sigma^2$：\\n$\\\\sum_{i=1}^{n} (x_i-\\\\mu) = 0$\\n$\\\\sum_{i=1}^{n} x_i - \\\\sum_{i=1}^{n} \\\\mu = 0$\\n$\\\\sum_{i=1}^{n} x_i - n\\\\mu = 0$\\n$n\\\\mu = \\\\sum_{i=1}^{n} x_i$\\n$\\\\hat{\\\\mu}_{MLE} = \\\\frac{1}{n} \\\\sum_{i=1}^{n} x_i = \\\\bar{x}$\\n\\n**2. 方差 $\\\\sigma^2$ 的最大似然估计：**\\n为了方便求导，我们令 $V = \\\\sigma^2$。对 $\\\\ln L$ 关于 $V$ 求偏导：\\n$\\\\frac{\\\\partial}{\\\\partial V} \\\\ln L = \\\\frac{\\\\partial}{\\\\partial V} \\\\left( -\\\\frac{n}{2} \\\\ln(2\\\\pi) - \\\\frac{n}{2} \\\\ln(V) - \\\\frac{1}{2V} \\\\sum_{i=1}^{n} (x_i-\\\\mu)^2 \\\\right)$\\n$= 0 - \\\\frac{n}{2} \\\\frac{1}{V} - \\\\frac{1}{2} \\\\sum_{i=1}^{n} (x_i-\\\\mu)^2 \\\\left( -\\\\frac{1}{V^2} \\\\right)$\\n$= -\\\\frac{n}{2V} + \\\\frac{1}{2V^2} \\\\sum_{i=1}^{n} (x_i-\\\\mu)^2$\\n\\n令偏导数等于零：\\n$-\\\\frac{n}{2V} + \\\\frac{1}{2V^2} \\\\sum_{i=1}^{n} (x_i-\\\\mu)^2 = 0$\\n将上式两边乘以 $2V^2$：\\n$-nV + \\\\sum_{i=1}^{n} (x_i-\\\\mu)^2 = 0$\\n$nV = \\\\sum_{i=1}^{n} (x_i-\\\\mu)^2$\\n$V = \\\\frac{1}{n} \\\\sum_{i=1}^{n} (x_i-\\\\mu)^2$\\n\\n将 $\\\\mu$ 的最大似然估计 $\\\\hat{\\\\mu}_{MLE} = \\\\bar{x}$ 代入上式，得到 $\\\\sigma^2$ 的最大似然估计：\\n$\\\\hat{\\\\sigma}^2_{MLE} = \\\\frac{1}{n} \\\\sum_{i=1}^{n} (x_i - \\\\bar{x})^2$\"\n",
      "}\n",
      "\n",
      "==================================================\n",
      "\n",
      "解析成功！\n",
      "答案:\n",
      "对于来自正态分布 $N(\\mu, \\sigma^2)$ 的 $n$ 个独立同分布样本 $x_1, x_2, \\ldots, x_n$，其最大似然估计（MLE）公式如下：\n",
      "\n",
      "1.  **均值 $\\mu$ 的最大似然估计：**\n",
      "    $\\hat{\\mu}_{MLE} = \\frac{1}{n} \\sum_{i=1}^{n} x_i = \\bar{x}$\n",
      "    （即样本均值）\n",
      "\n",
      "2.  **方差 $\\sigma^2$ 的最大似然估计：**\n",
      "    $\\hat{\\sigma}^2_{MLE} = \\frac{1}{n} \\sum_{i=1}^{n} (x_i - \\bar{x})^2$\n",
      "    （即有偏样本方差）\n",
      "\n",
      "说明:\n",
      "为了推导正态分布参数 $\\mu$ 和 $\\sigma^2$ 的最大似然估计，我们首先写出正态分布的概率密度函数（PDF）：\n",
      "$f(x | \\mu, \\sigma^2) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} e^{-\\frac{(x-\\mu)^2}{2\\sigma^2}}$\n",
      "\n",
      "给定 $n$ 个独立同分布的样本 $X = (x_1, x_2, \\ldots, x_n)$，似然函数 $L(\\mu, \\sigma^2 | X)$ 是各样本 PDF 的乘积：\n",
      "$L(\\mu, \\sigma^2 | X) = \\prod_{i=1}^{n} f(x_i | \\mu, \\sigma^2) = \\prod_{i=1}^{n} \\frac{1}{\\sqrt{2\\pi\\sigma^2}} e^{-\\frac{(x_i-\\mu)^2}{2\\sigma^2}}$\n",
      "$L(\\mu, \\sigma^2 | X) = (2\\pi\\sigma^2)^{-n/2} e^{-\\frac{1}{2\\sigma^2} \\sum_{i=1}^{n} (x_i-\\mu)^2}$\n",
      "\n",
      "为了简化计算，我们通常使用对数似然函数（log-likelihood function），因为对数函数是单调递增的，所以最大化似然函数等价于最大化对数似然函数：\n",
      "$\\ln L(\\mu, \\sigma^2 | X) = \\ln \\left( (2\\pi\\sigma^2)^{-n/2} e^{-\\frac{1}{2\\sigma^2} \\sum_{i=1}^{n} (x_i-\\mu)^2} \\right)$\n",
      "$\\ln L(\\mu, \\sigma^2 | X) = -\\frac{n}{2} \\ln(2\\pi\\sigma^2) - \\frac{1}{2\\sigma^2} \\sum_{i=1}^{n} (x_i-\\mu)^2$\n",
      "$\\ln L(\\mu, \\sigma^2 | X) = -\\frac{n}{2} \\ln(2\\pi) - \\frac{n}{2} \\ln(\\sigma^2) - \\frac{1}{2\\sigma^2} \\sum_{i=1}^{n} (x_i-\\mu)^2$\n",
      "\n",
      "接下来，我们对对数似然函数分别关于 $\\mu$ 和 $\\sigma^2$ 求偏导，并令其等于零，以找到最大值。\n",
      "\n",
      "**1. 均值 $\\mu$ 的最大似然估计：**\n",
      "对 $\\ln L$ 关于 $\\mu$ 求偏导：\n",
      "$\\frac{\\partial}{\\partial \\mu} \\ln L = \\frac{\\partial}{\\partial \\mu} \\left( -\\frac{n}{2} \\ln(2\\pi) - \\frac{n}{2} \\ln(\\sigma^2) - \\frac{1}{2\\sigma^2} \\sum_{i=1}^{n} (x_i-\\mu)^2 \\right)$\n",
      "$= 0 - 0 - \\frac{1}{2\\sigma^2} \\sum_{i=1}^{n} 2(x_i-\\mu)(-1)$\n",
      "$= \\frac{1}{\\sigma^2} \\sum_{i=1}^{n} (x_i-\\mu)$\n",
      "\n",
      "令偏导数等于零：\n",
      "$\\frac{1}{\\sigma^2} \\sum_{i=1}^{n} (x_i-\\mu) = 0$\n",
      "由于 $\\sigma^2 > 0$，我们可以将上式两边乘以 $\\sigma^2$：\n",
      "$\\sum_{i=1}^{n} (x_i-\\mu) = 0$\n",
      "$\\sum_{i=1}^{n} x_i - \\sum_{i=1}^{n} \\mu = 0$\n",
      "$\\sum_{i=1}^{n} x_i - n\\mu = 0$\n",
      "$n\\mu = \\sum_{i=1}^{n} x_i$\n",
      "$\\hat{\\mu}_{MLE} = \\frac{1}{n} \\sum_{i=1}^{n} x_i = \\bar{x}$\n",
      "\n",
      "**2. 方差 $\\sigma^2$ 的最大似然估计：**\n",
      "为了方便求导，我们令 $V = \\sigma^2$。对 $\\ln L$ 关于 $V$ 求偏导：\n",
      "$\\frac{\\partial}{\\partial V} \\ln L = \\frac{\\partial}{\\partial V} \\left( -\\frac{n}{2} \\ln(2\\pi) - \\frac{n}{2} \\ln(V) - \\frac{1}{2V} \\sum_{i=1}^{n} (x_i-\\mu)^2 \\right)$\n",
      "$= 0 - \\frac{n}{2} \\frac{1}{V} - \\frac{1}{2} \\sum_{i=1}^{n} (x_i-\\mu)^2 \\left( -\\frac{1}{V^2} \\right)$\n",
      "$= -\\frac{n}{2V} + \\frac{1}{2V^2} \\sum_{i=1}^{n} (x_i-\\mu)^2$\n",
      "\n",
      "令偏导数等于零：\n",
      "$-\\frac{n}{2V} + \\frac{1}{2V^2} \\sum_{i=1}^{n} (x_i-\\mu)^2 = 0$\n",
      "将上式两边乘以 $2V^2$：\n",
      "$-nV + \\sum_{i=1}^{n} (x_i-\\mu)^2 = 0$\n",
      "$nV = \\sum_{i=1}^{n} (x_i-\\mu)^2$\n",
      "$V = \\frac{1}{n} \\sum_{i=1}^{n} (x_i-\\mu)^2$\n",
      "\n",
      "将 $\\mu$ 的最大似然估计 $\\hat{\\mu}_{MLE} = \\bar{x}$ 代入上式，得到 $\\sigma^2$ 的最大似然估计：\n",
      "$\\hat{\\sigma}^2_{MLE} = \\frac{1}{n} \\sum_{i=1}^{n} (x_i - \\bar{x})^2$\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "system_prompt = \"\"\"\n",
    "你是一个数学助手。请用以下JSON格式回答问题：\n",
    "{\n",
    "  \"answer\": \"答案\",\n",
    "  \"explanation\": \"推导过程\"\n",
    "}\n",
    "\n",
    "请确保返回的是有效的JSON格式，不要包含任何额外的文本。\n",
    "\"\"\"\n",
    "\n",
    "user_question = \"Normal分布的最大似然估计(MLE)公式是什么？\"\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=system_prompt),\n",
    "    HumanMessage(content=user_question)\n",
    "]\n",
    "\n",
    "response = model.invoke(messages)\n",
    "print(\"原始回复:\")\n",
    "print(response.content)\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# 手动解析JSON\n",
    "try:\n",
    "    # 尝试解析JSON\n",
    "    content = str(response.content)\n",
    "    parsed_result = json.loads(content)\n",
    "    print(\"解析成功！\")\n",
    "    print(\"答案:\")\n",
    "    print(parsed_result[\"answer\"])\n",
    "    print(\"\\n解释:\")\n",
    "    print(parsed_result[\"explanation\"])\n",
    "except json.JSONDecodeError as e:\n",
    "    print(f\"JSON解析失败: {e}\")\n",
    "    print(\"原始内容:\")\n",
    "    print(response.content)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "### 方法二：使用 Pydantic + JSON Schema\n",
    "\n",
    "第二种方法是使用Pydantic定义数据模型，并使用JSON Schema来指导模型输出。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1687891",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class MathResponse(BaseModel):\n",
    "    answer: str = Field(description=\"详细的数学推导过程\")\n",
    "    explanation: str = Field(description=\"简要说明结果的含义\")\n",
    "\n",
    "structured_model = model.with_structured_output(MathResponse)\n",
    "\n",
    "user_question = \"请推导Normal分布的最大似然估计(MLE)公式\"\n",
    "\n",
    "print(\"使用Pydantic结构化输出:\")\n",
    "result = structured_model.invoke(user_question)\n",
    "\n",
    "print(\"类型:\", type(result))\n",
    "print(\"答案:\")\n",
    "print(result.answer)  # type: ignore\n",
    "print(\"\\n说明:\")\n",
    "print(result.explanation)  # type: ignore\n",
    "\n",
    "# 可以直接访问属性，也可以转换为字典\n",
    "print(\"\\n转换为字典:\")\n",
    "if hasattr(result, 'model_dump'):\n",
    "    result_dict = result.model_dump()  # type: ignore\n",
    "else:\n",
    "    result_dict = result\n",
    "print(result_dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f63b256",
   "metadata": {},
   "source": [
    "### 为什么不应该自己实现JSON模式？\n",
    "\n",
    "虽然方法一（手动解析JSON）看起来简单直接，但实际上存在许多问题：\n",
    "\n",
    "#### 1. 可靠性问题\n",
    "- **格式不稳定**：LLM可能返回不符合JSON格式的内容\n",
    "- **解析错误**：手动解析容易出现各种边界情况\n",
    "- **不一致性**：不同的调用可能返回不同的格式\n",
    "\n",
    "#### 2. 维护成本\n",
    "- **错误处理复杂**：需要处理各种解析异常\n",
    "- **格式验证**：需要手动验证字段是否存在和类型是否正确\n",
    "- **代码重复**：每个不同的结构都需要重新编写解析逻辑\n",
    "\n",
    "#### 3. 缺乏类型安全\n",
    "- **运行时错误**：字段访问错误只能在运行时发现\n",
    "- **IDE支持差**：无法获得代码补全和类型提示\n",
    "- **重构困难**：修改数据结构时容易遗漏更新\n",
    "\n",
    "#### 4. 结构化输出的优势\n",
    "- **内置验证**：自动验证数据类型和结构\n",
    "- **类型安全**：编译时检查，IDE支持完整\n",
    "- **一致性保证**：框架确保输出格式的一致性\n",
    "- **易于维护**：使用标准化的方式定义和使用数据结构\n",
    "\n",
    "#### 5. 最佳实践\n",
    "- **使用框架提供的结构化输出功能**\n",
    "- **定义清晰的Pydantic模型**\n",
    "- **利用类型系统提供的安全性**\n",
    "- **避免手动字符串解析**\n",
    "\n",
    "### 结论\n",
    "\n",
    "现代LLM框架（如LangChain）提供的结构化输出功能已经很成熟，可以自动处理JSON Schema生成、验证和解析。我们应该利用这些工具，而不是重新发明轮子。\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
