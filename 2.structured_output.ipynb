{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6251fbbf",
   "metadata": {},
   "source": [
    "## 结构化输出 (Structured Output)\n",
    "\n",
    "在这个notebook中，我们将演示如何让LLM返回结构化的数据格式，而不是纯文本。我们将使用与chatbot相同的例子：求Normal分布的最大似然估计(MLE)。\n",
    "\n",
    "### 为什么需要结构化输出？\n",
    "- 便于程序处理和解析\n",
    "- 减少格式错误\n",
    "- 提高数据的可靠性和一致性\n",
    "- 便于与其他系统集成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f82fd5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage, BaseMessage\n",
    "import dotenv\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "model = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "### 方法一：System Prompt + 手动解析 JSON\n",
    "\n",
    "第一种方法是在system prompt中明确要求模型返回特定的JSON格式，然后手动解析结果。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b8cf055",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始回复:\n",
      "```json\n",
      "{\n",
      "  \"answer\": \"对于一组独立同分布的样本 $x_1, x_2, \\ldots, x_n$ 来源于正态分布 $N(\\mu, \\sigma^2)$，其最大似然估计（MLE）公式如下：\\n\\n1.  **均值 (Mean) 的 MLE：**\\n    $\\\\hat{\\\\mu}_{MLE} = \\\\bar{x} = \\\\frac{1}{n} \\\\sum_{i=1}^n x_i$\\n\\n2.  **方差 (Variance) 的 MLE：**\\n    $\\\\hat{\\\\sigma}^2_{MLE} = \\\\frac{1}{n} \\\\sum_{i=1}^n (x_i - \\\\bar{x})^2$\",\n",
      "  \"explanation\": \"最大似然估计（MLE）的目标是找到使观测数据出现概率最大的参数值。对于正态分布，我们有其概率密度函数（PDF）：\\n$f(x|\\\\mu, \\\\sigma^2) = \\\\frac{1}{\\\\sqrt{2\\\\pi\\\\sigma^2}} e^{-\\\\frac{(x-\\\\mu)^2}{2\\\\sigma^2}}$\\n\\n1.  **构建似然函数 (Likelihood Function)：**\\n    对于 $n$ 个独立同分布的样本 $x_1, \\\\ldots, x_n$，似然函数是它们各自PDF的乘积：\\n    $L(\\\\mu, \\\\sigma^2) = \\\\prod_{i=1}^n f(x_i|\\\\mu, \\\\sigma^2) = \\\\left( \\\\frac{1}{2\\\\pi\\\\sigma^2} \\\\right)^{n/2} \\\\exp\\\\left( -\\\\frac{1}{2\\\\sigma^2}\\\\sum_{i=1}^n (x_i-\\\\mu)^2 \\\\right)$\\n\\n2.  **构建对数似然函数 (Log-Likelihood Function)：**\\n    为了简化计算，通常取似然函数的自然对数：\\n    $\\\\ln L(\\\\mu, \\\\sigma^2) = -\\\\frac{n}{2}\\\\ln(2\\\\pi) - \\\\frac{n}{2}\\\\ln(\\\\sigma^2) - \\\\frac{1}{2\\\\sigma^2}\\\\sum_{i=1}^n (x_i-\\\\mu)^2$\\n\\n3.  **对 \\\\mu 求偏导并令其为零：**\\n    $\\\\frac{\\\\partial \\\\ln L}{\\\\partial \\\\mu} = \\\\frac{1}{\\\\sigma^2} \\\\sum_{i=1}^n (x_i - \\\\mu)$\\n    令 $\\\\frac{\\\\partial \\\\ln L}{\\\\partial \\\\mu} = 0$，我们得到：\\n    $\\\\sum_{i=1}^n (x_i - \\\\mu) = 0 \\\\implies \\\\sum_{i=1}^n x_i - n\\\\mu = 0 \\\\implies \\\\hat{\\\\mu}_{MLE} = \\\\frac{1}{n} \\\\sum_{i=1}^n x_i = \\\\bar{x}$\\n\\n4.  **对 \\\\sigma^2 求偏导并令其为零：**\\n    设 $\\\\theta = \\\\sigma^2$ 以简化求导。\\n    $\\\\frac{\\\\partial \\\\ln L}{\\\\partial \\\\theta} = -\\\\frac{n}{2\\\\theta} + \\\\frac{1}{2\\\\theta^2}\\\\sum_{i=1}^n (x_i-\\\\mu)^2$\\n    令 $\\\\frac{\\\\partial \\\\ln L}{\\\\partial \\\\theta} = 0$，并将 \\\\mu 替换为 \\\\hat{\\\\mu}_{MLE} = \\\\bar{x}$：\\n    $-\\\\frac{n}{2\\\\hat{\\\\sigma}^2_{MLE}} + \\\\frac{1}{2(\\\\hat{\\\\sigma}^2_{MLE})^2}\\\\sum_{i=1}^n (x_i-\\\\bar{x})^2 = 0$\\n    $\\\\frac{n}{2\\\\hat{\\\\sigma}^2_{MLE}} = \\\\frac{1}{2(\\\\hat{\\\\sigma}^2_{MLE})^2}\\\\sum_{i=1}^n (x_i-\\\\bar{x})^2$\\n    $n = \\\\frac{1}{\\\\hat{\\\\sigma}^2_{MLE}}\\\\sum_{i=1}^n (x_i-\\\\bar{x})^2$\\n    $\\\\hat{\\\\sigma}^2_{MLE} = \\\\frac{1}{n} \\\\sum_{i=1}^n (x_i - \\\\bar{x})^2$\\n\\n需要注意的是，虽然 $\\\\hat{\\\\mu}_{MLE}$ 是样本均值，且是 \\\\mu 的无偏估计，但 $\\\\hat{\\\\sigma}^2_{MLE}$ 是样本方差的有偏估计量。无偏样本方差通常使用 $n-1$ 作为分母，即 $s^2 = \\\\frac{1}{n-1} \\\\sum_{i=1}^n (x_i - \\\\bar{x})^2$。\"\n",
      "}\n",
      "```\n",
      "\n",
      "==================================================\n",
      "\n",
      "JSON解析失败: Expecting value: line 1 column 1 (char 0)\n",
      "原始内容:\n",
      "```json\n",
      "{\n",
      "  \"answer\": \"对于一组独立同分布的样本 $x_1, x_2, \\ldots, x_n$ 来源于正态分布 $N(\\mu, \\sigma^2)$，其最大似然估计（MLE）公式如下：\\n\\n1.  **均值 (Mean) 的 MLE：**\\n    $\\\\hat{\\\\mu}_{MLE} = \\\\bar{x} = \\\\frac{1}{n} \\\\sum_{i=1}^n x_i$\\n\\n2.  **方差 (Variance) 的 MLE：**\\n    $\\\\hat{\\\\sigma}^2_{MLE} = \\\\frac{1}{n} \\\\sum_{i=1}^n (x_i - \\\\bar{x})^2$\",\n",
      "  \"explanation\": \"最大似然估计（MLE）的目标是找到使观测数据出现概率最大的参数值。对于正态分布，我们有其概率密度函数（PDF）：\\n$f(x|\\\\mu, \\\\sigma^2) = \\\\frac{1}{\\\\sqrt{2\\\\pi\\\\sigma^2}} e^{-\\\\frac{(x-\\\\mu)^2}{2\\\\sigma^2}}$\\n\\n1.  **构建似然函数 (Likelihood Function)：**\\n    对于 $n$ 个独立同分布的样本 $x_1, \\\\ldots, x_n$，似然函数是它们各自PDF的乘积：\\n    $L(\\\\mu, \\\\sigma^2) = \\\\prod_{i=1}^n f(x_i|\\\\mu, \\\\sigma^2) = \\\\left( \\\\frac{1}{2\\\\pi\\\\sigma^2} \\\\right)^{n/2} \\\\exp\\\\left( -\\\\frac{1}{2\\\\sigma^2}\\\\sum_{i=1}^n (x_i-\\\\mu)^2 \\\\right)$\\n\\n2.  **构建对数似然函数 (Log-Likelihood Function)：**\\n    为了简化计算，通常取似然函数的自然对数：\\n    $\\\\ln L(\\\\mu, \\\\sigma^2) = -\\\\frac{n}{2}\\\\ln(2\\\\pi) - \\\\frac{n}{2}\\\\ln(\\\\sigma^2) - \\\\frac{1}{2\\\\sigma^2}\\\\sum_{i=1}^n (x_i-\\\\mu)^2$\\n\\n3.  **对 \\\\mu 求偏导并令其为零：**\\n    $\\\\frac{\\\\partial \\\\ln L}{\\\\partial \\\\mu} = \\\\frac{1}{\\\\sigma^2} \\\\sum_{i=1}^n (x_i - \\\\mu)$\\n    令 $\\\\frac{\\\\partial \\\\ln L}{\\\\partial \\\\mu} = 0$，我们得到：\\n    $\\\\sum_{i=1}^n (x_i - \\\\mu) = 0 \\\\implies \\\\sum_{i=1}^n x_i - n\\\\mu = 0 \\\\implies \\\\hat{\\\\mu}_{MLE} = \\\\frac{1}{n} \\\\sum_{i=1}^n x_i = \\\\bar{x}$\\n\\n4.  **对 \\\\sigma^2 求偏导并令其为零：**\\n    设 $\\\\theta = \\\\sigma^2$ 以简化求导。\\n    $\\\\frac{\\\\partial \\\\ln L}{\\\\partial \\\\theta} = -\\\\frac{n}{2\\\\theta} + \\\\frac{1}{2\\\\theta^2}\\\\sum_{i=1}^n (x_i-\\\\mu)^2$\\n    令 $\\\\frac{\\\\partial \\\\ln L}{\\\\partial \\\\theta} = 0$，并将 \\\\mu 替换为 \\\\hat{\\\\mu}_{MLE} = \\\\bar{x}$：\\n    $-\\\\frac{n}{2\\\\hat{\\\\sigma}^2_{MLE}} + \\\\frac{1}{2(\\\\hat{\\\\sigma}^2_{MLE})^2}\\\\sum_{i=1}^n (x_i-\\\\bar{x})^2 = 0$\\n    $\\\\frac{n}{2\\\\hat{\\\\sigma}^2_{MLE}} = \\\\frac{1}{2(\\\\hat{\\\\sigma}^2_{MLE})^2}\\\\sum_{i=1}^n (x_i-\\\\bar{x})^2$\\n    $n = \\\\frac{1}{\\\\hat{\\\\sigma}^2_{MLE}}\\\\sum_{i=1}^n (x_i-\\\\bar{x})^2$\\n    $\\\\hat{\\\\sigma}^2_{MLE} = \\\\frac{1}{n} \\\\sum_{i=1}^n (x_i - \\\\bar{x})^2$\\n\\n需要注意的是，虽然 $\\\\hat{\\\\mu}_{MLE}$ 是样本均值，且是 \\\\mu 的无偏估计，但 $\\\\hat{\\\\sigma}^2_{MLE}$ 是样本方差的有偏估计量。无偏样本方差通常使用 $n-1$ 作为分母，即 $s^2 = \\\\frac{1}{n-1} \\\\sum_{i=1}^n (x_i - \\\\bar{x})^2$。\"\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "system_prompt = \"\"\"\n",
    "你是一个数学助手。请用以下JSON格式回答问题：\n",
    "{\n",
    "  \"answer\": \"答案\",\n",
    "  \"explanation\": \"推导过程\"\n",
    "}\n",
    "\n",
    "请确保返回的是有效的JSON格式，不要包含任何额外的文本。\n",
    "\"\"\"\n",
    "\n",
    "user_question = \"Normal分布的最大似然估计(MLE)公式是什么？\"\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=system_prompt),\n",
    "    HumanMessage(content=user_question)\n",
    "]\n",
    "\n",
    "response = model.invoke(messages)\n",
    "print(\"原始回复:\")\n",
    "print(response.content)\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# 手动解析JSON\n",
    "try:\n",
    "    # 尝试解析JSON\n",
    "    content = str(response.content)\n",
    "    parsed_result = json.loads(content)\n",
    "    print(\"解析成功！\")\n",
    "    print(\"答案:\")\n",
    "    print(parsed_result[\"answer\"])\n",
    "    print(\"\\n解释:\")\n",
    "    print(parsed_result[\"explanation\"])\n",
    "except json.JSONDecodeError as e:\n",
    "    print(f\"JSON解析失败: {e}\")\n",
    "    print(\"原始内容:\")\n",
    "    print(response.content)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "### 方法二：使用 Pydantic + JSON Schema\n",
    "\n",
    "第二种方法是使用Pydantic定义数据模型，并使用JSON Schema来指导模型输出。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1687891",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用Pydantic结构化输出:\n",
      "类型: <class '__main__.MathResponse'>\n",
      "答案:\n",
      "Normal分布的概率密度函数（PDF）为：\n",
      "$f(x | \\mu, \\sigma^2) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} e^{-\\frac{(x-\\mu)^2}{2\\sigma^2}}$\n",
      "\n",
      "对于一个包含 $n$ 个独立同分布（i.i.d.）样本 $X = \\{x_1, x_2, ..., x_n\\}$ 的数据集，其似然函数为：\n",
      "$L(\\mu, \\sigma^2 | X) = \\prod_{i=1}^{n} f(x_i | \\mu, \\sigma^2) = \\prod_{i=1}^{n} \\frac{1}{\\sqrt{2\\pi\\sigma^2}} e^{-\\frac{(x_i-\\mu)^2}{2\\sigma^2}}$\n",
      "\n",
      "为了简化计算，我们取似然函数的自然对数，得到对数似然函数：\n",
      "$ln L(\\mu, \\sigma^2 | X) = \\sum_{i=1}^{n} ln \\left( \\frac{1}{\\sqrt{2\\pi\\sigma^2}} e^{-\\frac{(x_i-\\mu)^2}{2\\sigma^2}} \\right)$\n",
      "$ln L(\\mu, \\sigma^2 | X) = \\sum_{i=1}^{n} \\left( -\\frac{1}{2}ln(2\\pi) - \\frac{1}{2}ln(\\sigma^2) - \\frac{(x_i-\\mu)^2}{2\\sigma^2} \\right)$\n",
      "$ln L(\\mu, \\sigma^2 | X) = -\\frac{n}{2}ln(2\\pi) - \\frac{n}{2}ln(\\sigma^2) - \\frac{1}{2\\sigma^2}\\sum_{i=1}^{n}(x_i-\\mu)^2$\n",
      "\n",
      "为了找到最大似然估计值，我们对对数似然函数分别关于 $\\mu$ 和 $\\sigma^2$ 求偏导数，并令其等于零。\n",
      "\n",
      "**1. 对 $\\mu$ 求偏导：**\n",
      "$\\frac{\\partial}{\\partial \\mu} ln L = \\frac{\\partial}{\\partial \\mu} \\left( -\\frac{n}{2}ln(2\\pi) - \\frac{n}{2}ln(\\sigma^2) - \\frac{1}{2\\sigma^2}\\sum_{i=1}^{n}(x_i-\\mu)^2 \\right)$\n",
      "$\\frac{\\partial}{\\partial \\mu} ln L = 0 - 0 - \\frac{1}{2\\sigma^2}\\sum_{i=1}^{n} 2(x_i-\\mu)(-1)$\n",
      "$\\frac{\\partial}{\\partial \\mu} ln L = \\frac{1}{\\sigma^2}\\sum_{i=1}^{n}(x_i-\\mu)$\n",
      "\n",
      "令 $\\frac{\\partial}{\\partial \\mu} ln L = 0$：\n",
      "$\\frac{1}{\\sigma^2}\\sum_{i=1}^{n}(x_i-\\mu) = 0$\n",
      "$\\sum_{i=1}^{n}(x_i-\\mu) = 0$\n",
      "$\\sum_{i=1}^{n}x_i - n\\mu = 0$\n",
      "$n\\mu = \\sum_{i=1}^{n}x_i$\n",
      "因此，$\\hat{\\mu}_{MLE} = \\frac{1}{n}\\sum_{i=1}^{n}x_i = \\bar{x}$\n",
      "\n",
      "**2. 对 $\\sigma^2$ 求偏导：**\n",
      "为了方便，令 $\\theta = \\sigma^2$。\n",
      "$\\frac{\\partial}{\\partial \\theta} ln L = \\frac{\\partial}{\\partial \\theta} \\left( -\\frac{n}{2}ln(2\\pi) - \\frac{n}{2}ln(\\theta) - \\frac{1}{2\\theta}\\sum_{i=1}^{n}(x_i-\\mu)^2 \\right)$\n",
      "$\\frac{\\partial}{\\partial \\theta} ln L = 0 - \\frac{n}{2\\theta} - \\frac{1}{2}\\left(-\\frac{1}{\\theta^2}\\right)\\sum_{i=1}^{n}(x_i-\\mu)^2$\n",
      "$\\frac{\\partial}{\\partial \\theta} ln L = -\\frac{n}{2\\theta} + \\frac{1}{2\\theta^2}\\sum_{i=1}^{n}(x_i-\\mu)^2$\n",
      "\n",
      "令 $\\frac{\\partial}{\\partial \\theta} ln L = 0$：\n",
      "$-\\frac{n}{2\\theta} + \\frac{1}{2\\theta^2}\\sum_{i=1}^{n}(x_i-\\mu)^2 = 0$\n",
      "两边乘以 $2\\theta^2$：\n",
      "$-n\\theta + \\sum_{i=1}^{n}(x_i-\\mu)^2 = 0$\n",
      "$n\\theta = \\sum_{i=1}^{n}(x_i-\\mu)^2$\n",
      "将 $\\theta = \\sigma^2$ 代回，并用 $\\hat{\\mu}_{MLE} = \\bar{x}$ 替换 $\\mu$：\n",
      "$\\hat{\\sigma}^2_{MLE} = \\frac{1}{n}\\sum_{i=1}^{n}(x_i-\\bar{x})^2$\n",
      "\n",
      "说明:\n",
      "Normal分布的最大似然估计结果表明，均值 $\\mu$ 的MLE是样本均值 $\\bar{x}$，而方差 $\\sigma^2$ 的MLE是样本方差 $\\frac{1}{n}\\sum_{i=1}^{n}(x_i-\\bar{x})^2$。需要注意的是，方差的MLE分母是 $n$，而不是无偏估计的 $n-1$。\n",
      "\n",
      "转换为字典:\n",
      "{'answer': 'Normal分布的概率密度函数（PDF）为：\\n$f(x | \\\\mu, \\\\sigma^2) = \\\\frac{1}{\\\\sqrt{2\\\\pi\\\\sigma^2}} e^{-\\\\frac{(x-\\\\mu)^2}{2\\\\sigma^2}}$\\n\\n对于一个包含 $n$ 个独立同分布（i.i.d.）样本 $X = \\\\{x_1, x_2, ..., x_n\\\\}$ 的数据集，其似然函数为：\\n$L(\\\\mu, \\\\sigma^2 | X) = \\\\prod_{i=1}^{n} f(x_i | \\\\mu, \\\\sigma^2) = \\\\prod_{i=1}^{n} \\\\frac{1}{\\\\sqrt{2\\\\pi\\\\sigma^2}} e^{-\\\\frac{(x_i-\\\\mu)^2}{2\\\\sigma^2}}$\\n\\n为了简化计算，我们取似然函数的自然对数，得到对数似然函数：\\n$ln L(\\\\mu, \\\\sigma^2 | X) = \\\\sum_{i=1}^{n} ln \\\\left( \\\\frac{1}{\\\\sqrt{2\\\\pi\\\\sigma^2}} e^{-\\\\frac{(x_i-\\\\mu)^2}{2\\\\sigma^2}} \\\\right)$\\n$ln L(\\\\mu, \\\\sigma^2 | X) = \\\\sum_{i=1}^{n} \\\\left( -\\\\frac{1}{2}ln(2\\\\pi) - \\\\frac{1}{2}ln(\\\\sigma^2) - \\\\frac{(x_i-\\\\mu)^2}{2\\\\sigma^2} \\\\right)$\\n$ln L(\\\\mu, \\\\sigma^2 | X) = -\\\\frac{n}{2}ln(2\\\\pi) - \\\\frac{n}{2}ln(\\\\sigma^2) - \\\\frac{1}{2\\\\sigma^2}\\\\sum_{i=1}^{n}(x_i-\\\\mu)^2$\\n\\n为了找到最大似然估计值，我们对对数似然函数分别关于 $\\\\mu$ 和 $\\\\sigma^2$ 求偏导数，并令其等于零。\\n\\n**1. 对 $\\\\mu$ 求偏导：**\\n$\\\\frac{\\\\partial}{\\\\partial \\\\mu} ln L = \\\\frac{\\\\partial}{\\\\partial \\\\mu} \\\\left( -\\\\frac{n}{2}ln(2\\\\pi) - \\\\frac{n}{2}ln(\\\\sigma^2) - \\\\frac{1}{2\\\\sigma^2}\\\\sum_{i=1}^{n}(x_i-\\\\mu)^2 \\\\right)$\\n$\\\\frac{\\\\partial}{\\\\partial \\\\mu} ln L = 0 - 0 - \\\\frac{1}{2\\\\sigma^2}\\\\sum_{i=1}^{n} 2(x_i-\\\\mu)(-1)$\\n$\\\\frac{\\\\partial}{\\\\partial \\\\mu} ln L = \\\\frac{1}{\\\\sigma^2}\\\\sum_{i=1}^{n}(x_i-\\\\mu)$\\n\\n令 $\\\\frac{\\\\partial}{\\\\partial \\\\mu} ln L = 0$：\\n$\\\\frac{1}{\\\\sigma^2}\\\\sum_{i=1}^{n}(x_i-\\\\mu) = 0$\\n$\\\\sum_{i=1}^{n}(x_i-\\\\mu) = 0$\\n$\\\\sum_{i=1}^{n}x_i - n\\\\mu = 0$\\n$n\\\\mu = \\\\sum_{i=1}^{n}x_i$\\n因此，$\\\\hat{\\\\mu}_{MLE} = \\\\frac{1}{n}\\\\sum_{i=1}^{n}x_i = \\\\bar{x}$\\n\\n**2. 对 $\\\\sigma^2$ 求偏导：**\\n为了方便，令 $\\\\theta = \\\\sigma^2$。\\n$\\\\frac{\\\\partial}{\\\\partial \\\\theta} ln L = \\\\frac{\\\\partial}{\\\\partial \\\\theta} \\\\left( -\\\\frac{n}{2}ln(2\\\\pi) - \\\\frac{n}{2}ln(\\\\theta) - \\\\frac{1}{2\\\\theta}\\\\sum_{i=1}^{n}(x_i-\\\\mu)^2 \\\\right)$\\n$\\\\frac{\\\\partial}{\\\\partial \\\\theta} ln L = 0 - \\\\frac{n}{2\\\\theta} - \\\\frac{1}{2}\\\\left(-\\\\frac{1}{\\\\theta^2}\\\\right)\\\\sum_{i=1}^{n}(x_i-\\\\mu)^2$\\n$\\\\frac{\\\\partial}{\\\\partial \\\\theta} ln L = -\\\\frac{n}{2\\\\theta} + \\\\frac{1}{2\\\\theta^2}\\\\sum_{i=1}^{n}(x_i-\\\\mu)^2$\\n\\n令 $\\\\frac{\\\\partial}{\\\\partial \\\\theta} ln L = 0$：\\n$-\\\\frac{n}{2\\\\theta} + \\\\frac{1}{2\\\\theta^2}\\\\sum_{i=1}^{n}(x_i-\\\\mu)^2 = 0$\\n两边乘以 $2\\\\theta^2$：\\n$-n\\\\theta + \\\\sum_{i=1}^{n}(x_i-\\\\mu)^2 = 0$\\n$n\\\\theta = \\\\sum_{i=1}^{n}(x_i-\\\\mu)^2$\\n将 $\\\\theta = \\\\sigma^2$ 代回，并用 $\\\\hat{\\\\mu}_{MLE} = \\\\bar{x}$ 替换 $\\\\mu$：\\n$\\\\hat{\\\\sigma}^2_{MLE} = \\\\frac{1}{n}\\\\sum_{i=1}^{n}(x_i-\\\\bar{x})^2$', 'explanation': 'Normal分布的最大似然估计结果表明，均值 $\\\\mu$ 的MLE是样本均值 $\\\\bar{x}$，而方差 $\\\\sigma^2$ 的MLE是样本方差 $\\\\frac{1}{n}\\\\sum_{i=1}^{n}(x_i-\\\\bar{x})^2$。需要注意的是，方差的MLE分母是 $n$，而不是无偏估计的 $n-1$。'}\n"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class MathResponse(BaseModel):\n",
    "    answer: str = Field(description=\"详细的数学推导过程\")\n",
    "    explanation: str = Field(description=\"简要说明结果的含义\")\n",
    "\n",
    "structured_model = model.with_structured_output(MathResponse)\n",
    "\n",
    "user_question = \"请推导Normal分布的最大似然估计(MLE)公式\"\n",
    "\n",
    "print(\"使用Pydantic结构化输出:\")\n",
    "result = structured_model.invoke(user_question)\n",
    "\n",
    "print(\"类型:\", type(result))\n",
    "print(\"答案:\")\n",
    "print(result.answer)  # type: ignore\n",
    "print(\"\\n说明:\")\n",
    "print(result.explanation)  # type: ignore\n",
    "\n",
    "# 可以直接访问属性，也可以转换为字典\n",
    "print(\"\\n转换为字典:\")\n",
    "if hasattr(result, 'model_dump'):\n",
    "    result_dict = result.model_dump()  # type: ignore\n",
    "else:\n",
    "    result_dict = result\n",
    "print(result_dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e45c8c7d",
   "metadata": {},
   "source": [
    "### Structured Output优点\n",
    "1. 稳定易用\n",
    "2. prompt与输出格式分离，方便维护\n",
    "3. 自动有pydantic的类型验证"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f63b256",
   "metadata": {},
   "source": [
    "### 为什么不应该自己实现JSON模式？\n",
    "\n",
    "虽然方法一（手动解析JSON）看起来简单直接，但实际上存在许多问题：\n",
    "\n",
    "#### 1. 可靠性问题\n",
    "- **格式不稳定**：LLM可能返回不符合JSON格式的内容\n",
    "- **解析错误**：手动解析容易出现各种边界情况\n",
    "\n",
    "#### 2. 维护成本\n",
    "- **错误处理复杂**：需要处理各种解析异常\n",
    "- **格式验证**：需要手动验证字段是否存在和类型是否正确\n",
    "- **代码重复**：每个不同的结构都需要重新编写解析逻辑\n",
    "\n",
    "#### 3. 缺乏类型安全\n",
    "- **运行时错误**：字段访问错误只能在运行时发现\n",
    "- **IDE支持差**：无法获得代码补全和类型提示\n",
    "- **重构困难**：修改数据结构时容易遗漏更新"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e8fe28",
   "metadata": {},
   "source": [
    "### 结论\n",
    "\n",
    "需要结构化输出的时候，\n",
    "1. 首先考虑无脑选择LangChain的with_structured_output\n",
    "2. 极少数情况，考虑使用JSON mode（Google, Anthropic已经放弃支持）\n",
    "3. 几乎不可能出现的情况：自己clean and parse JSON\n",
    "\n",
    "需要调用工具的时候，参考下一节，\n",
    "1. 首先无脑选择LangChain的 .bind_tools()\n",
    "2. 极少数情况，使用各家API的 function calling (tool calling) 功能\n",
    "3. 几乎不可能出现的情况：自己定义function calling的schema并试图parse"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
