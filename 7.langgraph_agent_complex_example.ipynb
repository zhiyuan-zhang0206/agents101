{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4027aa8c",
   "metadata": {},
   "source": [
    "## 一个稍微复杂一些的Coder Agent\n",
    "## 仅作示例，跑不动\n",
    "是我之前写的一个系统的一部分：https://github.com/zhiyuan-zhang0206/HomeworkAgent\n",
    "\n",
    "特点：\n",
    "- 采用最原始的JSON mode（当时OpenAI, LangChain的相关功能尚不完善）\n",
    "- 有3个node，human node, llm node, tool node。用户可以通过human node在任一阶段打断\n",
    "- 每个节点决定接下来到哪个节点，自由度高，不使用预先定义的图结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3dd215",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ..tools.files import read_file, write_file\n",
    "from ..tools.terminals import open_terminal, command_terminal, get_terminal_output, close_terminal\n",
    "from .member_agent import make_member_node\n",
    "\n",
    "\n",
    "CODER_ROLE_PROMPT = \"\"\"\n",
    "You will act as a coder agent.\n",
    "You can read and write files, open and close terminals, and get the output of a terminal.\n",
    "\"\"\"\n",
    "\n",
    "CODER_AGENT_NAME = \"coder_agent\"\n",
    "\n",
    "CODER_AGENT_ABILITIES = \"coder_agent can do some coding tasks. It can read and write pure text files, open and close terminals, and get the output of a terminal.\"\n",
    "\n",
    "\n",
    "coder_node = make_member_node(CODER_AGENT_NAME, \n",
    "                              CODER_ROLE_PROMPT, \n",
    "                              [read_file, \n",
    "                               write_file, \n",
    "                               open_terminal, \n",
    "                               command_terminal, \n",
    "                               get_terminal_output, \n",
    "                               close_terminal])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956a6d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import traceback\n",
    "from typing import Literal\n",
    "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage\n",
    "from langgraph.types import Command\n",
    "from loguru import logger\n",
    "from langchain_core.tools import BaseTool\n",
    "from langgraph.graph import StateGraph\n",
    "from .supervisor_agent_name import SUPERVISOR_AGENT_NAME\n",
    "from ..llms import MEMBER_DEFAULT_MODEL\n",
    "from .get_relevant_memories import get_relevant_memories\n",
    "from ..tools.notify_supervisor import notify_supervisor\n",
    "from ..llm_calling import get_and_parse_json_response\n",
    "from .memory_trigger_tools import is_trigger_memory_tool\n",
    "from .state import State\n",
    "def make_tools_prompt(tools: dict[str, BaseTool]):\n",
    "    return \"Tools specified below:\\n\" + \"\\n\\n\\n\".join(\n",
    "        [f\"Tool name: {name}:\\n{tool.description}\" for name, tool in tools.items()]\n",
    "    )\n",
    "\n",
    "MEMBER_PROMPT_TEMPLATE = \"\"\"\n",
    "You are an AI agent. You will output your thoughts and tool calls, the system will execute the tool calls and return the results to you.\n",
    "\n",
    "Response format specified below:\n",
    "Respond in JSON. Don't include \"```json\" nor \"```\" in your response.\n",
    "You should respond a JSON object with the following fields:\n",
    "- \"thoughts\": your thoughts about the task,\n",
    "- \"tool_calls\": a list of tool calls you are calling, this should never be empty,\n",
    "    - \"name\": the tool name to call,\n",
    "    - \"args\": the arguments to pass to the tool.\n",
    "\n",
    "If you need assistance or clarification use the \"notify_supervisor\" tool and put your assistant request in the \"summary\" field.\n",
    "If you have completed your task, call the \"notify_supervisor\" tool and put your summary in the \"summary\" field.\n",
    "The supervisor agent is responsible for orchestrating the overall task and can provide guidance or delegate sub-tasks if necessary.\n",
    "\n",
    "Example 1:\n",
    "{\n",
    "    \"thoughts\": \"The supervisor told me about ... Now I need to read the file D:/math/questions.md.\",\n",
    "    \"tool_calls\": [\n",
    "        {\n",
    "            \"name\": \"read_file\",\n",
    "            \"args\": {\n",
    "                \"filepath\": \"D:/math/questions.md\"\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "Example 2:\n",
    "{\n",
    "    \"thoughts\": \"The math problem describes... I should solve it this way... After writing the solution into the file, I will call notify_supervisor.\",\n",
    "    \"tool_calls\": [\n",
    "        {\n",
    "            \"name\": \"write_file\",\n",
    "            \"args\": {\n",
    "                \"filepath\": \"D:/report.md\",\n",
    "                \"content\": \"We first consider...\"\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "Example 3:\n",
    "{\n",
    "    \"thoughts\": \"Based on the feedback from tools, ... So I should call notify_supervisor as the only tool call.\",\n",
    "    \"tool_calls\": [\n",
    "        {\n",
    "            \"name\": \"notify_supervisor\",\n",
    "            \"args\": {\n",
    "                \"summary\": \"I solved the math problems and saved the solutions in file D:/report.md.\"\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def make_member_llm_node(agent_name: str, role_prompt: str, llm = MEMBER_DEFAULT_MODEL, tools: dict[str, BaseTool] = {}):\n",
    "    def llm_node(state: State) -> Command[Literal[agent_name, \"tools\"]]:  # type: ignore\n",
    "        logger.info(f\"Entering {agent_name} llm_node.\")\n",
    "\n",
    "        # Initialize agent's message history if it's a new agent call\n",
    "        if agent_name not in state[\"member_messages\"]:\n",
    "            system_prompt = (\n",
    "                MEMBER_PROMPT_TEMPLATE\n",
    "                + f\"\\nYour role:\\n{role_prompt}\\n\\n\"\n",
    "                + make_tools_prompt(tools)\n",
    "            )\n",
    "            state[\"member_messages\"][agent_name] = [SystemMessage(content=system_prompt)]\n",
    "            state[\"member_tool_calls\"][agent_name] = []\n",
    "            state[\"member_trigger_long_term_memory\"][agent_name] = False\n",
    "            state[\"member_retrieved_memory_ids\"][agent_name] = []\n",
    "\n",
    "        if state[\"next_agent_prompt\"]:\n",
    "            prompt = state[\"next_agent_prompt\"]\n",
    "            logger.info(f\"{agent_name} llm_node processing prompt from supervisor: {prompt}\")\n",
    "            state[\"member_messages\"][agent_name].append(HumanMessage(content=f\"Supervisor message: {prompt}\"))\n",
    "            state[\"member_tool_calls\"][agent_name] = []\n",
    "            state[\"member_trigger_long_term_memory\"][agent_name] = True\n",
    "            state[\"member_retrieved_memory_ids\"][agent_name] = []\n",
    "            state[\"next_agent_prompt\"] = None\n",
    "            return Command(update=state, goto=agent_name)\n",
    "\n",
    "        agent_messages = state[\"member_messages\"][agent_name]\n",
    "\n",
    "        if state[\"member_trigger_long_term_memory\"].get(agent_name, False): # Use .get() to avoid KeyError if agent_name not in dict\n",
    "            logger.info(f\"{agent_name} retrieving memories\")\n",
    "            retrieved_memory_ids = state[\"member_retrieved_memory_ids\"].get(agent_name, []) # Use .get()\n",
    "            _, memory_ids, memory_formatted = get_relevant_memories(agent_messages, exclude_ids=retrieved_memory_ids)\n",
    "            retrieved_memory_ids.extend(memory_ids)\n",
    "            agent_messages[-1].content = agent_messages[-1].content + memory_formatted\n",
    "            state[\"member_retrieved_memory_ids\"][agent_name].extend(retrieved_memory_ids)\n",
    "            state[\"member_trigger_long_term_memory\"][agent_name] = False\n",
    "            return Command(update=state, goto=agent_name)\n",
    "        else:\n",
    "            logger.info(f\"{agent_name} no memory trigger tool calls, skipping memory retrieval\")\n",
    "\n",
    "        response, parsed_response = get_and_parse_json_response(llm, agent_messages)\n",
    "        agent_messages.append(AIMessage(content=response))\n",
    "        try:\n",
    "            thoughts, tool_calls = parsed_response[\"thoughts\"], parsed_response[\"tool_calls\"]\n",
    "        except KeyError:\n",
    "            logger.warning(f\"{agent_name} error parsing JSON response: {parsed_response}\")\n",
    "            agent_messages.append(\n",
    "                HumanMessage(\n",
    "                    content=\"System: reminder: you should include one and only one 'thoughts' and 'tool_calls' field in your response.\"\n",
    "                )\n",
    "            )\n",
    "            state[\"member_tool_calls\"][agent_name] = []\n",
    "            state[\"member_trigger_long_term_memory\"][agent_name] = False\n",
    "            return Command(update=state, goto=agent_name)\n",
    "        if not tool_calls:\n",
    "            logger.warning(f\"{agent_name} did not return any tool calls; reminding LLM.\")\n",
    "            agent_messages.append(\n",
    "                HumanMessage(\n",
    "                    content=\"System: reminder: you should call at least one tool. If everything is done, call the tool 'notify_supervisor'.\"\n",
    "                )\n",
    "            )\n",
    "            state[\"member_tool_calls\"][agent_name] = []\n",
    "            state[\"member_trigger_long_term_memory\"][agent_name] = False\n",
    "            return Command(update=state, goto=agent_name)\n",
    "        logger.info(f\"{agent_name} llm_node called, going to tools_node\")\n",
    "        state[\"member_tool_calls\"][agent_name] = tool_calls\n",
    "        state[\"member_trigger_long_term_memory\"][agent_name] = False\n",
    "        return Command(goto=\"member_human_node\", update=state)\n",
    "    return llm_node\n",
    "\n",
    "def make_member_human_node(agent_name: str):\n",
    "    def human_node(state: State) -> Command[Literal[agent_name, \"tools\"]]:  # type: ignore\n",
    "        value = input(\"Input your instruction here. Leave blank if you don't have any:\\nInstruction: \").strip()\n",
    "        if value:\n",
    "            logger.info(f\"Human instruction: {value}\")\n",
    "            messages = state[\"member_messages\"][agent_name]\n",
    "            messages.append(HumanMessage(content=f'System: None of the tool calls are executed because human interrupted with instruction message: {value}'))\n",
    "            return Command(goto=agent_name, update=state)\n",
    "        else:\n",
    "            logger.info(f\"No human instruction, going to tools_node\")\n",
    "            return Command(goto=\"tools\")\n",
    "    return human_node\n",
    "\n",
    "def make_member_tools_node(agent_name: str, tools: dict[str, BaseTool], return_to_supervisor: bool = True):\n",
    "    def tools_node(state: State) -> Command[Literal[agent_name]]:  # type: ignore\n",
    "        logger.info(f\"Entering {agent_name} tools_node.\")\n",
    "        tool_calls = state[\"member_tool_calls\"][agent_name]\n",
    "        messages = state[\"member_messages\"][agent_name]\n",
    "        \n",
    "        if len(tool_calls) == 0:\n",
    "            logger.warning(f\"{agent_name} no tool calls\")\n",
    "            messages.append(\n",
    "                HumanMessage(\n",
    "                    content=\"System: reminder: you should call at least one tool. If everything is done, call the tool 'notify_supervisor'.\"\n",
    "                )\n",
    "            )\n",
    "            state[\"member_trigger_long_term_memory\"][agent_name] = False\n",
    "            return Command(goto=agent_name, update=state)\n",
    "        \n",
    "        if len(tool_calls) > 1 and any(tool_call[\"name\"] == \"notify_supervisor\" for tool_call in tool_calls):\n",
    "            logger.warning(f\"{agent_name} called notify_supervisor but there are still tools to call\")\n",
    "            messages.append(\n",
    "                HumanMessage(\n",
    "                    content=\"System: No tool calls are executed. Reminder: \\\"notify_supervisor\\\" cannot be used with other tools. It should be the only tool call when you have verified all tool call outputs and decided to stop.\"\n",
    "                )\n",
    "            )\n",
    "            state[\"member_trigger_long_term_memory\"][agent_name] = False\n",
    "            return Command(goto=agent_name, update=state)\n",
    "        \n",
    "        # Handle notify_supervisor tool call\n",
    "        if len(tool_calls) == 1 and tool_calls[0][\"name\"] == \"notify_supervisor\":\n",
    "            notify_call = tool_calls[0]\n",
    "            notify_result = tools[\"notify_supervisor\"].invoke(notify_call[\"args\"])\n",
    "            logger.info(f\"{agent_name} notify_supervisor call: {notify_call} produced result: {notify_result}\")\n",
    "            notify_message = notify_call[\"args\"][\"summary\"]\n",
    "            logger.info(f\"{agent_name} notify supervisor with message: {notify_message}\")\n",
    "            if return_to_supervisor:\n",
    "                logger.info(f\"{agent_name} returning control to supervisor\")\n",
    "                state[\"member_finish_message\"][agent_name] = notify_message\n",
    "                state[\"member_tool_calls\"][agent_name] = []\n",
    "                state[\"member_trigger_long_term_memory\"][agent_name] = False\n",
    "                return Command(goto=SUPERVISOR_AGENT_NAME, graph=Command.PARENT, update=state)\n",
    "            else:\n",
    "                logger.info(f\"{agent_name} returning notify message in a dict\")\n",
    "                return {\"notify_supervisor_message\": notify_message}\n",
    "\n",
    "        for tool_call in tool_calls:\n",
    "            if tool_call[\"name\"] not in tools:\n",
    "                logger.warning(f\"{agent_name} unknown tool: {tool_call['name']}\")\n",
    "                messages.append(\n",
    "                    HumanMessage(\n",
    "                        content=f\"System: None tool calls are executed because tool {tool_call['name']} not found, please try again.\"\n",
    "                    )\n",
    "                )\n",
    "                state[\"member_trigger_long_term_memory\"][agent_name] = False\n",
    "                return Command(goto=agent_name, update=state)\n",
    "\n",
    "        tool_call_results = []\n",
    "        for tool_call in tool_calls:\n",
    "            tool_name = tool_call[\"name\"]\n",
    "            try:\n",
    "                tool_result = tools[tool_name].invoke(tool_call[\"args\"])\n",
    "            except Exception as e:\n",
    "                tool_result = f\"Error: {e}\"\n",
    "                logger.warning(f\"{agent_name} tool call: {tool_call} produced error: {e}. Traceback: {traceback.format_exc()}\")\n",
    "            tool_call_results.append((tool_name, tool_result))\n",
    "            logger.info(f\"{agent_name} tool call: {tool_call} produced result: {tool_result}\")\n",
    "        \n",
    "        results_message = \"\\n\".join(\n",
    "            [f'Tool \"{name}\" result: {result}' for name, result in tool_call_results]\n",
    "        )\n",
    "        messages.append(HumanMessage(content=results_message))\n",
    "        logger.info(f\"{agent_name} not finished, going back to llm_node\")\n",
    "        state[\"member_trigger_long_term_memory\"][agent_name] = any(is_trigger_memory_tool(call[\"name\"]) for call in tool_calls)\n",
    "        state[\"member_tool_calls\"][agent_name] = []\n",
    "        return Command(update=state, goto=agent_name)\n",
    "    return tools_node\n",
    "\n",
    "def make_member_node(agent_name: str, role_prompt: str, tools: list[BaseTool], \n",
    "                     llm = MEMBER_DEFAULT_MODEL,\n",
    "                     return_to_supervisor: bool = True):\n",
    "    tools = {tool.name: tool for tool in tools}\n",
    "    tools[\"notify_supervisor\"] = notify_supervisor\n",
    "    subgraph = StateGraph(State)\n",
    "    subgraph.add_node(agent_name, make_member_llm_node(agent_name, role_prompt, llm, tools))\n",
    "    subgraph.add_node(\"member_human_node\", make_member_human_node(agent_name))\n",
    "    subgraph.add_node(\"tools\", make_member_tools_node(agent_name, tools, return_to_supervisor))\n",
    "    subgraph.set_entry_point(agent_name)\n",
    "    subgraph = subgraph.compile()\n",
    "    return subgraph"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
